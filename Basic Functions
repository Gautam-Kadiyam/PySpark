# Importing packages
import pyspark
from pyspark.sql import SparkSession
from pyspark.sql.functions import *

# Initilization of Spark Session
spark=SparkSession.builder.appName("Can be anything").getOrCreate()

# Reading csv file
# Csv file is available in Pyspark folder
df=spark.read.csv("Products.csv",header=True,inferSchema=True)

# Shows the output of the dataframe df which is read from the csv file
df.show()

# 1.Selecting column Brand from csv file
df.select("Brand").show()

# 2.Filtering column Color from csv file
df.filter(col("Color")=="ForestGreen").show()

# 3.Column Renaming for Availability column from csv file
df.withColumnRenamed("Availability","Inventory").show()

# 4.Distinct value of Availability column from csv file
df.select("Availability").distinct().show()

# 5.Sorting Ascending and Descending Order for Category column from csv file
df.sort("Category",ascending=True).show()
df.sort("Category",ascending=False).show()

# 6.New Column addition for stock with value *5
col_add=df.withColumn("Stock*5",col("Stock")*5)
col_add.show()

# 7.Dropping column Stock*5 from the table
col_add=col_add.drop("Stock*5")
col_add.show()

# 8.Persist and how to take count of dataset from csv file
# Persist function is used to store the result of the dataframe in memory instead of reading the dataframe from the start i.e.,it will start from the creation of spark
# session. Time saving to use the persist() function.
df.persist()
df.count()

# 9.Grouping with aggregations such as Mean,Mode,Median,First,Last,Sum,Avg




